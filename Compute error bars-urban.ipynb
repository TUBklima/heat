{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "#import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "import ulmo\n",
    "import os\n",
    "import scipy.spatial\n",
    "import scipy.stats\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotting utilities\n",
    "def lin_trend_plot(start_x, y,title, xlabel, ylabel) : \n",
    "# plots x,y (need to be np array) and calculates and prints their best fit line\n",
    "    ind = ~np.isnan(y.values)# & ~np.isnan(x) # subset values that aren't NaNs\n",
    "    x = np.arange(0,y.shape[0])\n",
    "    m, b, r_value, p, std_err = scipy.stats.linregress(x[ind],y[ind])\n",
    "    plt.scatter(x+start_x,y)\n",
    "    plt.plot(x+start_x, m*x+b, color = 'black')\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "    # annotate the linear reqression, y = mx+b\n",
    "    plt.annotate('y = %.2f x + %.2f'%(m,b), xy=(.5, .9), xycoords='axes fraction',  horizontalalignment='left', verticalalignment='bottom')\n",
    "    plt.annotate('r = %.2f'%(r_value), xy=(.5, .85), xycoords='axes fraction',  horizontalalignment='left', verticalalignment='bottom')\n",
    "    plt.annotate('p = %.2f'%(p), xy=(.5, .8), xycoords='axes fraction',  horizontalalignment='left', verticalalignment='bottom')\n",
    "    plt.annotate('N = %i'%(ind.shape), xy=(.5, .75), xycoords='axes fraction',  horizontalalignment='left', verticalalignment='bottom')\n",
    "    return m, b, r_value, p, std_err\n",
    "\n",
    "def easy_scatter(x,y,title, xlabel, ylabel) : \n",
    "# plots x,y (need to be np array) and calculates and prints their best fit line\n",
    "    ind = ~np.isnan(y) & ~np.isnan(x) # subset values that aren't NaNs\n",
    "    m,b = np.polyfit(x[ind],y[ind],1)\n",
    "    r, p = scipy.stats.pearsonr(x[ind], y[ind]) #np.corrcoef(x[ind],y[ind])[0,1]\n",
    "    plt.scatter(x,y)\n",
    "    plt.plot(x, m*x+b, color = 'black')\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "    # annotate the linear reqression, y = mx+b\n",
    "    plt.annotate('y = %.2f x + %.2f'%(m,b), xy=(.5, .9), xycoords='axes fraction',  horizontalalignment='left', verticalalignment='bottom')\n",
    "    plt.annotate('r = %.2f'%(r), xy=(.5, .85), xycoords='axes fraction',  horizontalalignment='left', verticalalignment='bottom')\n",
    "    plt.annotate('p = %.2f'%(p), xy=(.5, .8), xycoords='axes fraction',  horizontalalignment='left', verticalalignment='bottom')\n",
    "    plt.annotate('N = %i'%(ind.shape), xy=(.5, .75), xycoords='axes fraction',  horizontalalignment='left', verticalalignment='bottom')\n",
    "    return m, r, p\n",
    "\n",
    "def how_UHI_varies(mean_UHIs, closeststations_distance): \n",
    "    plt.figure(figsize= [12,4])\n",
    "    plt.subplot(1,3,1)\n",
    "    data = mean_UHIs[~np.isnan(mean_UHIs)]\n",
    "    plt.hist(data)\n",
    "    plt.xlabel('$\\Delta T$ ($\\Delta ^\\circ$C)')\n",
    "    plt.ylabel('Count')\n",
    "    plt.annotate('min = %.2f'%(data.min()), xy=(0, .94), xycoords='axes fraction',  horizontalalignment='left', verticalalignment='bottom')\n",
    "    plt.annotate('max = %.2f'%(data.max()), xy=(0, .89), xycoords='axes fraction',  horizontalalignment='left', verticalalignment='bottom')\n",
    "    plt.annotate('$\\mu$ = %.2f'%(data.mean()), xy=(0, .84), xycoords='axes fraction',  horizontalalignment='left', verticalalignment='bottom')\n",
    "    plt.annotate('$\\sigma$ = %.2f'%(data.std()), xy=(0, .79), xycoords='axes fraction',  horizontalalignment='left', verticalalignment='bottom')\n",
    "    plt.title('Histogram of $\\Delta T$')\n",
    "\n",
    "    plt.subplot(1,3,2)\n",
    "    m,r,p = easy_scatter(closeststations_distance, mean_UHIs, \n",
    "                 'Distance to rural station vs. $\\Delta T$ ', \n",
    "             'Distance to rural station (degrees lat/lon)', '$\\Delta T$ ($\\Delta ^\\circ$C)',\n",
    "             )\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    m2,r2,p2 = easy_scatter(ghcn.loc[rural_station_list].Brightness.values, mean_UHIs, \n",
    "                 'Brightness versus $\\Delta T$', \n",
    "                 'Satellite Brightness Index', '$\\Delta T$ ($\\Delta ^\\circ$C)',\n",
    "                 )\n",
    "    return m,r,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annascott2/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:12: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "/Users/annascott2/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:18: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n"
     ]
    }
   ],
   "source": [
    "# readin in GHCN data \n",
    "ghcn = pd.read_fwf('data/ghcnd-stations.txt', colspecs = [(0,11), (12,19), (21,29), (31,36),(38,40), (41,70), (72,74),(76,78),(80,85)], header = None) \n",
    "colnames = ['GHCN ID', 'lat', 'lon', 'elevation', 'state', 'name', 'gsn flag', 'HCN/CRN FLAG', 'WMO ID']\n",
    "ghcn.columns = colnames\n",
    "\n",
    "# append the brightness index \n",
    "BI = np.load('data/brightnessGHCN.npy')\n",
    "ghcn['Brightness'] = BI\n",
    "\n",
    "currentstations = ulmo.ncdc.ghcn_daily.get_stations(start_year=1985, end_year = 2016, elements = ['TMIN', 'TMAX', 'AWND'], as_dataframe=True, update=False)\n",
    "currentGHCNstations = np.intersect1d(currentstations.id, ghcn['GHCN ID'].values)\n",
    "ghcnSubset = ghcn.set_index('GHCN ID').loc[currentstations.id.values]\n",
    "# at this point, ghcn must have the station id set as the index \n",
    "\n",
    "ghcn_noairport = ghcn[~ghcn.name.str.contains('INTL')]\n",
    "ghcn_noairport = ghcn_noairport[~ghcn_noairport.name.str.contains(' AP')]\n",
    "ghcn_noairport = ghcn_noairport[~ghcn_noairport.name.str.contains('AIRPORT')]\n",
    "ghcn = ghcn_noairport.set_index('GHCN ID').loc[currentstations.id.values]\n",
    "\n",
    "# generate atlas of cities and k-d tree \n",
    "atlas = pd.read_csv('data/world_cities.csv')\n",
    "atlas = atlas[(atlas['country'] == 'United States of America')]# & (atlas['pop']>100000)]\n",
    "atlas = atlas.set_index('city')\n",
    "tree = scipy.spatial.cKDTree(ghcn[['lon', 'lat']].values, leafsize=100)\n",
    "#atlas = atlas[atlas['pop']> 500000]\n",
    "\n",
    "paired_df = pd.read_csv('USpairs2005-2015.csv').set_index('City', drop = False)\n",
    "paired_df = paired_df[paired_df['Urban distance'] < 0.25]\n",
    "\n",
    "results = np.ones([paired_df.shape[0],11])*np.nan # save out min,max, mean, std, m,r,p\n",
    "results_filepath = 'plots/version7/errorbars/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!mkdir plots/version7/errorbars\n",
    "!mkdir plots/version7/errorbars/trend\n",
    "!mkdir plots/version7/errorbars/slopes\n",
    "!mkdir plots/version7/errorbars/values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ascott47/anaconda/lib/python3.6/site-packages/ulmo/ncdc/ghcn_daily/core.py:89: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  axis=1)\n",
      "/Users/ascott47/anaconda/lib/python3.6/site-packages/ulmo/ncdc/ghcn_daily/core.py:95: FutureWarning: \n",
      ".resample() is now a deferred operation\n",
      "You called index(...) on this deferred object which materialized it into a dataframe\n",
      "by implicitly taking the mean.  Use .resample(...).mean() instead\n",
      "  daily_index = element_df.resample('D').index.copy()\n"
     ]
    }
   ],
   "source": [
    "city = 'Mesa'\n",
    "### Set variables\n",
    "print(city)\n",
    "urbanID = paired_df.loc[city]['Urban station']\n",
    "urbandata = ulmo.ncdc.ghcn_daily.get_data(urbanID,\n",
    "                                     as_dataframe=True, update = False)\n",
    "urban_tmin = pd.to_numeric(urbandata['TMIN']['2000-01-01':].value/10.) \n",
    "urban_tmin.loc[urbandata['TMIN']['2000-01-01':]['qflag'].dropna().index] = np.nan\n",
    "urban_summer = urban_tmin[(urban_tmin.index.month >= 6) & (urban_tmin.index.month <= 8)]\n",
    "# set lat/lon\n",
    "try: # if  \n",
    "    if atlas[atlas.index==city].shape[0]>1 : # if more than one hit for the city, eg, Kansas City (MO and KS)\n",
    "            lat = atlas.loc[city]['lat'][0]\n",
    "            lon = atlas.loc[city]['lng'] [1]\n",
    "    else: \n",
    "        lat = atlas[atlas['pop']> 300000].loc[city]['lat']\n",
    "        lon = atlas[atlas['pop']> 300000].loc[city]['lng']        \n",
    "# try to fix if there are two such cities in the atlas; take the second one\n",
    "except IndexError: \n",
    "    lat = atlas[atlas['pop']> 300000].loc[city]['lat'][1]\n",
    "    lon = atlas[atlas['pop']> 300000].loc[city]['lng'][1]\n",
    "# find the closest stations\n",
    "closeststations = tree.query([lon,lat], k =35, distance_upper_bound=1.5) #used in pairing algorithm: .5\n",
    "cols = ['Distance', 'Index', 'GHCNID', 'Brightness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33.423914609999997, -111.73608440000001)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat, lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.08292739,  0.09221545,  0.15282465,  0.17957532,  0.18491879,\n",
       "         0.22573856,  0.24113618,  0.2579119 ,  0.3215709 ,  0.32743828,\n",
       "         0.33666198,  0.34675309,  0.35318386,  0.35533968,  0.38165245,\n",
       "         0.39480938,  0.42021496,  0.42535645,  0.42784842,  0.47419441,\n",
       "         0.47860788,  0.52119142,  0.53750026,  0.59025405,  0.60893941,\n",
       "         0.62185774,  0.63139606,  0.63681901,  0.64329358,  0.64584151,\n",
       "         0.65098671,  0.67889616,  0.69537766,  0.83784176,  0.84701399]),\n",
       " array([11159, 11113, 11211, 11121, 11230, 11096, 11223, 11062, 11164,\n",
       "        11187, 11221, 22627, 11196, 22404, 11108, 11069, 11149, 11090,\n",
       "        11154, 11092, 22407, 11117, 11091, 11259, 11192, 11194, 11151,\n",
       "        11195, 19291, 19368, 11227, 11115, 11064, 11094, 11184]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closeststations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.odr import Model, Data, ODR\n",
    "from scipy.stats import linregress\n",
    "def f(B, x):\n",
    "    '''Linear function y = m*x + b'''\n",
    "    # B is a vector of the parameters.\n",
    "    # x is an array of the current x values.\n",
    "    # x is in the same format as the x passed to Data or RealData.\n",
    "    #\n",
    "    # Return an array in the same format as y passed to Data or RealData.\n",
    "    return B[0]*x + B[1]\n",
    "\n",
    "def easy_scatter_tls(x,y,title='', xlabel='', ylabel='', text_y_loc = .9 , text_x_loc = .5) : \n",
    "        linear = Model(f)\n",
    "        ind = ~np.isnan(y) & ~np.isnan(x)\n",
    "        linreg = scipy.stats.linregress(x[ind], y[ind])\n",
    "        mydata = Data(x[ind], y[ind])\n",
    "        myodr = ODR(mydata, linear, beta0=linreg[0:2]) # beta0 are initial guesses for paremeter values, ie, intercept and slope\n",
    "        myoutput = myodr.run()\n",
    "        # t-test for tls regression coeff\n",
    "        DF = y[ind].shape[0] -2 # for a linear model\n",
    "        b1 = myoutput.beta[0] # slope\n",
    "        H0 = 1 # null hypothesis\n",
    "        SE = myoutput.sd_beta[0]\n",
    "        t = (b1-H0)/SE\n",
    "        p = scipy.stats.t.cdf(t,df=DF)\n",
    "        # plot it  \n",
    "        plt.plot(x, f(myoutput.beta, x), 'k')\n",
    "        plt.plot(np.linspace(x.min(), x.max(), 20),np.linspace(x.min(), x.max(), 20), '--k' )\n",
    "        plt.scatter(x,y,color = 'grey', alpha =.5)\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.legend(['y = %.2f x + %.2f'%(myoutput.beta[0], myoutput.beta[1]),\n",
    "                    '1-1 line', 'Data'], loc=2, frameon =False)\n",
    "        plt.title(title)\n",
    "        return myoutput.beta[0], myoutput.beta[1],linreg.rvalue, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "ee.Initialize()\n",
    "\n",
    "nlcd = ee.Image('USGS/NLCD/NLCD2011').select('landcover')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "developed\n"
     ]
    }
   ],
   "source": [
    "lcc = 21\n",
    "if (lcc >20) & (lcc <=24) : \n",
    "    print('developed')\n",
    "else: \n",
    "    print('not developed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salt Lake City\n",
      "no overlapping data\n",
      "1.07209303697\n",
      "1.0286418353\n",
      "no overlapping data\n",
      "0.91902397808\n",
      "no overlapping data\n",
      "Omaha\n",
      "1.02962054566\n",
      "1.05058232862\n",
      "0.940590236684\n",
      "Raleigh\n",
      "0.837685818352\n",
      "0.942532138729\n",
      "not urban\n",
      "0.910775312377\n",
      "Cleveland\n",
      "1.03174082377\n",
      "Cincinnati\n",
      "1.07921222753\n",
      "1.08408549517\n",
      "Nashville\n",
      "not urban\n",
      "0.956849774323\n",
      "not urban\n",
      "not urban\n",
      "1.0126921451\n",
      "1.039792624\n",
      "Memphis\n",
      "0.930001945716\n",
      "0.872208262003\n",
      "0.957121671077\n",
      "Norfolk\n",
      "Not enough urban stations for Norfolk\n",
      "Milwaukee\n",
      "0.994939102871\n",
      "1.00350547973\n",
      "1.013637353\n",
      "0.979195178111\n",
      "0.952088456345\n",
      "Buffalo\n",
      "1.04714582509\n",
      "0.982352284997\n",
      "Pittsburgh\n",
      "not urban\n",
      "not urban\n",
      "not urban\n",
      "1.09682054418\n",
      "Minneapolis\n",
      "0.83312659481\n",
      "0.9076743661\n",
      "0.853595815987\n",
      "0.93347569675\n",
      "not urban\n",
      "Honolulu\n",
      "not urban\n",
      "not urban\n",
      "not urban\n",
      "not urban\n",
      "not urban\n",
      "not urban\n",
      "Seattle\n",
      "0.875890714682\n",
      "no overlapping data\n",
      "0.837742284221\n",
      "no overlapping data\n",
      "0.891851648127\n",
      "Phoenix\n",
      "not urban\n",
      "no overlapping data\n",
      "0.901353308942\n",
      "1.11743288262\n",
      "1.1288163613\n",
      "San Diego\n",
      "0.338468796121\n",
      "not urban\n",
      "0.269690376675\n",
      "0.27353856902\n",
      "0.265013001835\n",
      "0.305146891386\n",
      "not urban\n",
      "St. Louis\n",
      "0.945904303289\n",
      "0.960684515332\n",
      "New Orleans\n",
      "not urban\n",
      "0.881697610163\n",
      "not urban\n",
      "0.895028869907\n",
      "not urban\n",
      "Dallas\n",
      "1.02586943673\n",
      "no overlapping data\n",
      "not urban\n",
      "Philadelphia\n",
      "0.789953001018\n",
      "no overlapping data\n",
      "no overlapping data\n",
      "no overlapping data\n",
      "0.73072107544\n",
      "no overlapping data\n",
      "0.732900671914\n",
      "Detroit\n",
      "not urban\n",
      "0.937281385988\n",
      "not urban\n",
      "not urban\n",
      "0.983165381217\n",
      "0.915596320067\n",
      "1.03316892725\n",
      "San Francisco\n",
      "0.689364808931\n",
      "0.774156901575\n",
      "0.755338957504\n",
      "0.626592044055\n",
      "Denver\n",
      "0.653518243572\n",
      "0.57950819692\n",
      "0.618938626732\n",
      "no overlapping data\n",
      "0.668423885511\n",
      "not urban\n",
      "0.619679450581\n",
      "not urban\n",
      "not urban\n",
      "Miami\n",
      "0.855435259483\n",
      "1.00656835744\n",
      "0.775842400256\n",
      "not urban\n",
      "0.612571206181\n",
      "0.579941708676\n",
      "Chicago\n",
      "0.86767460742\n",
      "no overlapping data\n",
      "0.889027635759\n",
      "Los Angeles\n",
      "0.287686189239\n",
      "0.238370845008\n",
      "0.334643034856\n",
      "0.43643611861\n",
      "not urban\n",
      "0.225729322817\n",
      "Washington, D.C.\n",
      "0.981470878691\n",
      "not urban\n",
      "0.987687707807\n",
      "not urban\n",
      "not urban\n",
      "New York\n",
      "not urban\n",
      "no overlapping data\n",
      "no overlapping data\n",
      "0.901702245728\n",
      "0.702039214202\n",
      "0.901558735733\n",
      "no overlapping data\n"
     ]
    }
   ],
   "source": [
    "brightness_threshold = 25\n",
    "#redo_cities = np.where(np.isnan(results[:,0]))[0]\n",
    "for city in paired_df.index[26:]:\n",
    "    ### Set variables\n",
    "    print(city)\n",
    "    ruralID = paired_df.loc[city]['Rural station']\n",
    "    ruraldata = ulmo.ncdc.ghcn_daily.get_data(ruralID,\n",
    "                                         as_dataframe=True, update = False)\n",
    "    rural_tmin = pd.to_numeric(ruraldata['TMIN']['2000-01-01':].value/10.) \n",
    "    rural_tmin.loc[ruraldata['TMIN']['2000-01-01':]['qflag'].dropna().index] = np.nan\n",
    "    rural_summer = rural_tmin[(rural_tmin.index.month >= 6) & (rural_tmin.index.month <= 8)]\n",
    "    #urban_summer = urban_tmin[(urban_tmin.index.month >= 6) & (urban_tmin.index.month <= 8)]\n",
    "            # set lat/lon\n",
    "    try: # if  \n",
    "        if city == 'Grand Prairie': \n",
    "                lat = atlas.loc['Arlington']['lat']\n",
    "                lon = atlas.loc['Arlington']['lng']\n",
    "        elif atlas[atlas.index==city].shape[0]>1 : # if more than one hit for the city, eg, Kansas City (MO and KS)\n",
    "                lat = atlas.loc[city]['lat'][0]\n",
    "                lon = atlas.loc[city]['lng'][1]\n",
    "        else: \n",
    "            lat = atlas[atlas['pop']> 300000].loc[city]['lat']\n",
    "            lon = atlas[atlas['pop']> 300000].loc[city]['lng']        \n",
    "    # try to fix if there are two such cities in the atlas; take the second one\n",
    "    except IndexError: \n",
    "        lat = atlas[atlas['pop']> 300000].loc[city]['lat'][1]\n",
    "        lon = atlas[atlas['pop']> 300000].loc[city]['lng'][1]\n",
    "\n",
    "    # find the closest stations\n",
    "    closeststations = tree.query([lon,lat], k =35, distance_upper_bound=1.5) #used in pairing algorithm: .5\n",
    "    cols = ['Distance', 'Index', 'GHCNID', 'Brightness']\n",
    "    try: \n",
    "        # get station ids\n",
    "        stations = pd.DataFrame(np.array([closeststations[0][~np.isinf(closeststations[0])].astype(float),\n",
    "                                          closeststations[1][~np.isinf(closeststations[0])],\n",
    "                                          ghcn.iloc[closeststations[1][~np.isinf(closeststations[0])]]['Brightness'].index,\n",
    "                                          ghcn.iloc[closeststations[1][~np.isinf(closeststations[0])]]['Brightness'].values]).T, \n",
    "                    columns = cols).set_index('GHCNID').drop(ruralID)\n",
    "        stations = stations[~np.isinf(stations['Distance'].values.astype(float))]\n",
    "    except IndexError: \n",
    "        closeststations = closeststations[0]\n",
    "        stations = pd.DataFrame(np.array([closeststations[0].astype(float),closeststations[1], ghcn.iloc[closeststations[1]]['Brightness'].index, ghcn.iloc[closeststations[1]]['Brightness'].values]).T, \n",
    "                columns = cols).set_index('GHCNID').drop(ruralID)\n",
    "        stations = stations[~np.isinf(stations['Distance'].values.astype(float))]\n",
    "    except ValueError: # got this when urban ID wasn't in the stations for Jacksonville, should maybe check\n",
    "        stations = pd.DataFrame(np.array([closeststations[0].astype(float),closeststations[1], ghcn.iloc[closeststations[1]]['Brightness'].index, ghcn.iloc[closeststations[1]]['Brightness'].values]).T, \n",
    "            columns = cols).set_index('GHCNID')#.drop(urbanID)\n",
    "        stations = stations[~np.isinf(stations['Distance'].values.astype(float))]\n",
    "    #rural_stations = stations.index\n",
    "    # select only dim stations\n",
    "    urban_station_list = stations[stations.Brightness > 45].index\n",
    "    urban_distance = stations[stations.Brightness > 45].Distance.values.astype(float)\n",
    "    \n",
    "    urban_station_list = urban_station_list[urban_distance < .2]\n",
    "     # if there are rural stations available, do analysis\n",
    "    if len(urban_station_list) > 0 :# & (ind.sum() > 0): \n",
    "        # preallocate\n",
    "        mean_urban = np.ones(len(urban_station_list))*np.nan\n",
    "        mean_ms = np.ones(len(urban_station_list))*np.nan\n",
    "        mean_rs = np.ones(len(urban_station_list))*np.nan\n",
    "        mean_ps = np.ones(len(urban_station_list))*np.nan\n",
    "        mean_Trslopes =  np.ones(len(urban_station_list))*np.nan\n",
    "        \n",
    "        ii = 0 \n",
    "        # loop over rural stations\n",
    "        for urban_id in urban_station_list: #[2:] :\n",
    "            point = ee.Geometry.Point([ghcn.loc[urban_id].lon,ghcn.loc[urban_id].lat])\n",
    "            #point = ee.Geometry.Point([ghcn.loc[urban_station_list[0]].lon,ghcn.loc[urban_station_list[0]].lat])\n",
    "            # sample the data of the NLCD at this location\n",
    "            data = nlcd.sample(point,30).getInfo()\n",
    "            try: \n",
    "                lcc = data['features'][0]['properties']['landcover']\n",
    "            except IndexError: \n",
    "                lcc = np.nan\n",
    "            if (lcc >20) & (lcc <=24) & (ghcn.loc[urban_id].Brightness-ghcn.loc[ruralID].Brightness >25): \n",
    "                # read in rural data\n",
    "                urbandata = ulmo.ncdc.ghcn_daily.get_data(urban_id, as_dataframe=True, update=False)\n",
    "                ###### Import data\n",
    "                urban_tmin = pd.to_numeric(urbandata['TMIN']['2000-01-01':].value/10.) #rural tmin\n",
    "                # drop data with flags here\n",
    "                urban_tmin.loc[urbandata['TMIN']['2000-01-01':]['qflag'].dropna().index] = np.nan\n",
    "                # extract summertime data \n",
    "                urban_summer = urban_tmin[(urban_tmin.index.month >= 6) & (urban_tmin.index.month <= 8)]            \n",
    "                ###### calculate slope \n",
    "\n",
    "                ind = ~np.isnan(urban_summer) & ~np.isnan(urban_summer[rural_summer.index])\n",
    "                if ind.sum() > 0 :\n",
    "                    x = rural_summer\n",
    "                    y = urban_summer\n",
    "                    linear = Model(f)\n",
    "                    ind = ~np.isnan(y) & ~np.isnan(x)\n",
    "                    linreg = scipy.stats.linregress(x[ind], y[ind])\n",
    "                    mydata = Data(x[ind], y[ind])\n",
    "                    myodr = ODR(mydata, linear, beta0=linreg[0:2]) # beta0 are initial guesses for paremeter values, ie, intercept and slope\n",
    "                    myoutput = myodr.run()\n",
    "                    m = myoutput.beta[0]\n",
    "                    mean_ms[ii] = m\n",
    "                    print(m)\n",
    "                else: \n",
    "                    print('no overlapping data')\n",
    "            else:\n",
    "                print('not urban')\n",
    "            ii = ii+1\n",
    "#       #  print(mean_ms)\n",
    "        #np.save(results_filepath+'trend/'+ city.replace(\" \", \"\")[0:5]+'Trtrend.npy', mean_Trslopes)\n",
    "        np.save(results_filepath+'slopes/'+ city.replace(\" \", \"\")[0:5]+'m_urban.npy', mean_ms)\n",
    "        np.save(results_filepath+'slopes/'+ city.replace(\" \", \"\")[0:5]+'urban_distance.npy', urban_distance[urban_distance <.2])\n",
    "        #np.save(results_filepath+'slopes/'+ city.replace(\" \", \"\")[0:5]+'r.npy', mean_ms)\n",
    "        #np.save(results_filepath+'slopes/'+ city.replace(\" \", \"\")[0:5]+'p.npy', mean_ps)\n",
    "        #np.save(results_filepath+'values/'+ city.replace(\" \", \"\")[0:5]+'rural.npy', mean_rural)\n",
    "    else: \n",
    "        print( 'Not enough urban stations for %s'%city)\n",
    "#     if np.mod(i,10) == 0 : \n",
    "#         np.savetxt(results_filepath+'results.csv', results, delimiter = ',')\n",
    "        \n",
    "#np.savetxt(results_filepath+'results.csv', results, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Salt Lake City', u'Omaha', u'Raleigh', u'Cleveland', u'Cincinnati',\n",
       "       u'Nashville', u'Memphis', u'Norfolk', u'Milwaukee', u'Buffalo',\n",
       "       u'Pittsburgh', u'Minneapolis', u'Honolulu', u'Seattle', u'Phoenix',\n",
       "       u'San Diego', u'St. Louis', u'New Orleans', u'Dallas', u'Philadelphia',\n",
       "       u'Detroit', u'San Francisco', u'Denver', u'Miami', u'Chicago',\n",
       "       u'Los Angeles', u'Washington, D.C.', u'New York'],\n",
       "      dtype='object', name=u'City')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired_df.index[26:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fort Lauderdale'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'USC00414597', u'USW00093901', u'USC00410337', u'USW00013960'], dtype='object', name=u'GHCNID')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urban_station_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>elevation</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>gsn flag</th>\n",
       "      <th>HCN/CRN FLAG</th>\n",
       "      <th>WMO ID</th>\n",
       "      <th>Brightness</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GHCNID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>USC00414597</th>\n",
       "      <td>32.640</td>\n",
       "      <td>-96.974</td>\n",
       "      <td>180.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>JOE POOL LAKE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USW00093901</th>\n",
       "      <td>32.733</td>\n",
       "      <td>-96.966</td>\n",
       "      <td>150.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>DALLAS HENSLEY FLD NAS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USC00410337</th>\n",
       "      <td>32.757</td>\n",
       "      <td>-97.073</td>\n",
       "      <td>163.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>ARLINGTON SIX FLAGS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USW00013960</th>\n",
       "      <td>32.851</td>\n",
       "      <td>-96.855</td>\n",
       "      <td>134.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>DALLAS LOVE FLD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72258.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                lat     lon  elevation state                    name gsn flag  \\\n",
       "GHCNID                                                                          \n",
       "USC00414597  32.640 -96.974      180.0    TX           JOE POOL LAKE      NaN   \n",
       "USW00093901  32.733 -96.966      150.0    TX  DALLAS HENSLEY FLD NAS      NaN   \n",
       "USC00410337  32.757 -97.073      163.0    TX     ARLINGTON SIX FLAGS      NaN   \n",
       "USW00013960  32.851 -96.855      134.0    TX         DALLAS LOVE FLD      NaN   \n",
       "\n",
       "            HCN/CRN FLAG   WMO ID  Brightness  \n",
       "GHCNID                                         \n",
       "USC00414597          NaN      NaN        59.0  \n",
       "USW00093901          NaN      NaN        62.0  \n",
       "USC00410337          NaN      NaN        63.0  \n",
       "USW00013960          NaN  72258.0        63.0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ghcn.loc[urban_station_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.06435467,  0.07258676,  0.08945549,  0.23439122])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urban_distance[urban_distance<.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr = np.ones(len(urban_station_list))\n",
    "i =0\n",
    "for urban_id in urban_station_list:\n",
    "    point = ee.Geometry.Point([ghcn.loc[urban_id].lon,ghcn.loc[urban_id].lat])\n",
    "    # sample the data of the NLCD at this location\n",
    "    data = nlcd.sample(point,30).getInfo()\n",
    "    lcc = data['features'][0]['properties']['landcover']\n",
    "    arr[i] = lcc\n",
    "    i= i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 43.,  22.,  23.,  23.,  22.,  23.,  23.])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0301089 ,  0.07750495,  0.1551334 ,  0.15673238,  0.15697906,\n",
       "        0.17598603,  0.17937529,  0.2806035 ,  0.29373218,  0.29445688,\n",
       "        0.29560228,  0.31410249,  0.31556151,  0.3333158 ,  0.34675558,\n",
       "        0.35311453,  0.35701827,  0.36246311,  0.37304836,  0.3731582 ,\n",
       "        0.38039605,  0.40296671,  0.42942603,  0.43503905,  0.43923663,\n",
       "        0.44684735,  0.46644918,  0.47666916,  0.48441935,  0.49346895,\n",
       "        0.51333183,  0.52656896])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urban_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Oakland', u'West Palm Beach', u'Louisville', u'Columbus',\n",
       "       u'San Bernardino', u'St. Paul', u'Tucson', u'Fresno', u'Albuquerque',\n",
       "       u'Kansas City', u'Ft. Worth', u'Austin', u'Indianapolis', u'Baltimore',\n",
       "       u'San Jose', u'Sacramento', u'Las Vegas', u'Portland',\n",
       "       u'Salt Lake City', u'Omaha', u'Raleigh', u'Cleveland', u'Cincinnati',\n",
       "       u'Nashville', u'Memphis', u'Norfolk', u'Milwaukee', u'Buffalo',\n",
       "       u'Pittsburgh', u'Minneapolis', u'Honolulu', u'Seattle', u'Phoenix',\n",
       "       u'San Diego', u'St. Louis', u'New Orleans', u'Dallas', u'Philadelphia',\n",
       "       u'Detroit', u'San Francisco', u'Denver', u'Miami', u'Chicago',\n",
       "       u'Los Angeles', u'Washington, D.C.', u'New York'],\n",
       "      dtype='object', name=u'City')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired_df.index[8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oakland'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05182397,  0.05414334,  0.07897238,  0.09608563,  0.11204732,\n",
       "        0.15641196,  0.20489944,  0.21639673])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urban_distance[urban_distance < .25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0198254 ,  0.07309721,  0.07992144,  0.09302259,  0.09801534,\n",
       "        0.11404239,  0.14398662,  0.18398444,  0.20992983])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urban_distance[urban_distance < .25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'USC00025467', u'USC00022782', u'USC00027661', u'USC00023190',\n",
       "       u'USC00028499', u'USC00026603', u'USC00028112', u'USW00093140',\n",
       "       u'USC00027370', u'USW00053156', u'USC00022462', u'USC00021282',\n",
       "       u'USC00021314', u'USW00053162', u'USC00023027', u'USC00021306',\n",
       "       u'USC00029634', u'USC00024977'],\n",
       "      dtype='object', name=u'GHCNID')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if (lcc >20) & (lcc <=24) & (ghcn.loc[ruralID].Brightness - ghcn.loc[urban_id]) > 25: \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ghcn.loc[urban_id].Brightness-ghcn.loc[ruralID].Brightness >25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ghcn.loc[ruralID].Brightness - ghcn.loc[urbanID]) > 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
